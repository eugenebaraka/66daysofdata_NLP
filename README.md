# 66daysofdata_NLP

## Resources

### Books
- [Natural Language Processing with Python](https://www.nltk.org/book/)



# Day 1 of 66daysofdata

On my journey of #66daysofdata, I decided to start with the basics of Natural Language Processing (NLP). Today, I started with familiarizing myself with the NLTK library as well as some of the fundamental vocabularies (tokens, types, and lexical richness). **Tokens** are the number of characters in a text. **Types** are distinct and unique tokens in a text while **lexical richness** is the percentage of distinct tokens in a text. See you again tomorrow!

Book:
[Chapter 1. Natural Language Processing with Python](https://www.nltk.org/book/)

![lexical richness](./images/day1.PNG)

# Day 2 of 66daysofdata

Today, I touched on the overview of NLP usecase, including speech recognition, machine translation, and textual entailment. I also learned that NLP still has a lot of limitations such as performing common-sense reasoning or drawing on world knowledge to perform tasks. Here's is my image of the day. It explains the spoken dialog system pipeline. Now I have a high level understanding of how my Google Assistant works! Can't wait for tomorrow!

Book:
[Chapter 1. Natural Language Processing with Python](https://www.nltk.org/book/)

![spoken dialog system](./images/day2.PNG)

# Day 3 of 66daysofdata

I continued my journey by learning about WordNet and semantic similarity. WordNet is a lexical database of English words and their meaning. This is very useful in finding how close/similar two words are to each other by calculating their semantic similarity, which takes values 0 to 1, and the more similar are the closer to 1 their semantic similarity will be. Below is the calculated semantic similarity between the words "car" and "vehicle". Excited to learn more about how this concept is applied to a real-world NLP task. See you tomorrow!

Book:
[Chapter 2. Natural Language Processing with Python](https://www.nltk.org/book/)

![semantic similarity](./images/day3.PNG)