{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from urllib import request\n",
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scrape my blog's feed, select the my latest blog, \n",
    "\n",
    "def parse_blog(feed_url):\n",
    "    \"\"\"\n",
    "    Input: takes the feed url\n",
    "    Output: returns the parsed latest blog\n",
    "    \"\"\"\n",
    "\n",
    "    all_feed = feedparser.parse(feed_url)\n",
    "    latest_post = all_feed[\"entries\"][0]\n",
    "    post_content = latest_post.content[0].value\n",
    "    #I slice the first element to remove the the dictionary inside the list\n",
    "\n",
    "    # generate raw text and tokenize it\n",
    "    raw_text = BeautifulSoup(post_content, \"html.parser\").get_text()\n",
    "    # tokenized_text = word_tokenize(raw_text)\n",
    "\n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Understanding Population Variance and Sample Variance Formulas\\nIn my data science learning journey, I set a goal to really understand the fundamental topics before moving on to advanced ones. Instead of striving to learn as many things as I can, I sl'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading blog post\n",
    "my_latest_blog = parse_blog(\"https://eugenebaraka.github.io/feed.xml\")\n",
    "my_latest_blog[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenizing the text using Regex\n",
    "pattern = r''' (?x)         #setting flag to allow verbose regexps for better readability\n",
    "        ([A-Z]\\.)+          #this will keep abbreviations such U.S.A\n",
    "        |\\w+(-\\w+)        #this will hyphenated words\n",
    "        |\\$?\\d+(\\.\\d+)?%? #this will keep currency (dollar) and percentages, and numbers\n",
    "        |\\.\\.\\.            #this keeps ellipses\n",
    "        # |[][.,;\"'?():-_']  #more tokens to include which includes ] and [\n",
    "'''\n",
    "\n",
    "tokenized_blog = nltk.regexp_tokenize(my_latest_blog, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_blog[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(?x) # set flag to allow verbose regexps\n",
    " ([A-Z]\\.)+ # abbreviations, e.g. U.S.A.\n",
    "    | \\w+(-\\w+)* # words with optional internal hyphens\n",
    "    | \\$?\\d+(\\.\\d+)?%? # currency and percentages, e.g. $12.40, 82%\n",
    "    | \\.\\.\\. # ellipsis\n",
    "    | [][.,;\"'?():-_'] # these are separate tokens; includes ], [\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', '', ''),\n",
       " ('A.', '', ''),\n",
       " ('', '-print', ''),\n",
       " ('', '', ''),\n",
       " ('', '', '.40'),\n",
       " ('', '', '')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'That U.S.A. poster-print costs $12.40...'\n",
    "tokenized_blog = nltk.regexp_tokenize(text, pattern)\n",
    "tokenized_blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'U.S.A'\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
