{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consecutive classication or greedy classication: finding the most likely class label for the first input then use that answer to find the best label for the next input. The process is repeated until all inputs have been labelled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    \"\"\"\n",
    "\n",
    "    Function to extract features from a sentence. \n",
    "\n",
    "    History argument provides a list of tags that have already been predicted\n",
    "    in the sentence so far. Each tag in history will correspond to a word in \n",
    "    sentence. \n",
    "    \n",
    "    Function returns features extracted from each word of the sentence, i.e., \n",
    "    suffix1, suffix2, suffix3\n",
    "    \"\"\"\n",
    "    features = {'suffix1': sentence[i][-1:], \n",
    "                'suffix2': sentence[i][-2:],\n",
    "                'suffix3': sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features['prev_word'] = '<START>'\n",
    "        features['prev_tag'] = '<START>'\n",
    "\n",
    "    else:\n",
    "        features['prev_word'] = sentence[i-1]\n",
    "        features['prev_tag'] = history[i-1]\n",
    "\n",
    "    return features\n",
    "\n",
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "\n",
    "    def __init(self, train_sents):\n",
    "\n",
    "        \"\"\" \n",
    "        The function builds a sequence classifier based on the history of the \n",
    "        previous words\n",
    "        \"\"\"\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                feature_set = pos_features(untagged_sent, i, history)\n",
    "                train_set.append((feature_set, tag))\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            feature_set = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(feature_set)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_set, test_set = tagged_sents[size:], tagged_sents[:size]\n",
    "tagger = ConsecutivePosTagger(train_set)\n",
    "print(tagger.evaluate(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPEECH AND LANGUAGE PROCESSING 3rd Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
